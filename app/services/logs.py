"""
Log service for creating processing run audit logs.

This module generates structured audit logs for each processing run,
providing transparency and debugging information.
"""

import re
from datetime import datetime
from pathlib import Path
from typing import Any


class LogService:
    """
    Manages creation of processing run logs in the configured logs folder.

    Each processing run gets a timestamped log file documenting:
    - Which dumps were processed
    - Which files were created/modified
    - Processing duration and cost
    - Any errors that occurred
    """

    def __init__(self, logs_dir: Path, vault_path: Path | None = None):
        """
        Initialize log service.

        Args:
            logs_dir: Absolute path to logs directory
            vault_path: Optional absolute path to vault root (for relative path computation)
        """
        self.logs_dir = logs_dir
        self.vault_path = vault_path

    def create_run_log(
        self,
        duration_seconds: float,
        cost_usd: float | None = None,
        error: str | None = None,
    ) -> Path:
        """
        Create a processing run log file.

        Creates the logs directory if it doesn't exist.

        Args:
            duration_seconds: Processing duration in seconds
            cost_usd: API cost in USD (if available)
            error: Error message (if processing failed)

        Returns:
            Path to created log file (relative to vault root)
        """
        # Create logs directory on-demand
        self.logs_dir.mkdir(parents=True, exist_ok=True)

        timestamp = datetime.utcnow()
        run_id = timestamp.strftime("%Y-%m-%dT%H-%M-%SZ")
        filename = f"run-{run_id}.md"
        file_path = self.logs_dir / filename

        # Build log content
        content = f"""# Processing Run: {timestamp.isoformat()}Z

## Summary

- **Duration**: {duration_seconds:.1f}s
"""

        # Add cost if available
        if cost_usd is not None:
            content += f"- **Cost**: ${cost_usd:.4f}\n"

        # Add status
        if error:
            content += f"- **Status**: ❌ FAILED\n- **Error**: {error}\n"
        else:
            content += "- **Status**: ✅ SUCCESS\n"

        # Add footer
        content += "\n---\n*Generated by Prime Agent*\n*Changes tracked in git commit*\n"

        # Write log file
        file_path.write_text(content, encoding="utf-8")

        # Return relative path to vault root if available, otherwise absolute path
        if self.vault_path:
            return file_path.relative_to(self.vault_path)
        return file_path

    def get_last_run(self) -> dict[str, Any] | None:
        """
        Read the most recent processing run log.

        Returns:
            Dict with run metadata or None if no logs exist
        """
        if not self.logs_dir.exists():
            return None

        # Find all run logs
        log_files = sorted(self.logs_dir.glob("run-*.md"), reverse=True)
        if not log_files:
            return None

        # Read the most recent log
        latest_log = log_files[0]
        content = latest_log.read_text(encoding="utf-8")

        # Parse metadata from content
        result: dict[str, Any] = {}

        # Extract timestamp from filename: run-2026-01-02T19-25-00Z.md
        timestamp_match = re.search(r"run-(\d{4}-\d{2}-\d{2}T\d{2}-\d{2}-\d{2}Z)", latest_log.name)
        if timestamp_match:
            timestamp_str = timestamp_match.group(1).replace("-", ":", 2)  # Fix time part
            result["timestamp"] = timestamp_str.replace("T", "T").replace("Z", "Z")

        # Extract duration
        duration_match = re.search(r"\*\*Duration\*\*: ([\d.]+)s", content)
        if duration_match:
            result["duration_seconds"] = float(duration_match.group(1))

        # Extract cost
        cost_match = re.search(r"\*\*Cost\*\*: \$([\d.]+)", content)
        if cost_match:
            result["cost_usd"] = float(cost_match.group(1))

        # Extract status
        if "✅ SUCCESS" in content:
            result["status"] = "success"
        elif "❌ FAILED" in content:
            result["status"] = "failed"
            # Extract error message
            error_match = re.search(r"\*\*Error\*\*: (.+)", content)
            if error_match:
                result["error"] = error_match.group(1).strip()

        # Note: dumps_processed count is not currently tracked in logs
        # Could be added in future if needed
        result["dumps_processed"] = 0

        return result
