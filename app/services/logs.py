"""
Log service for creating processing run audit logs.

This module generates structured audit logs for each processing run,
providing transparency and debugging information.
"""

from __future__ import annotations

import re
from datetime import UTC, datetime
from typing import TYPE_CHECKING, Any

from app.exceptions import VaultError

if TYPE_CHECKING:
    from pathlib import Path

    from app.models.command_run_log import CommandRunGitSummary, CommandRunSummary
    from app.services.vault import VaultService


class LogService:
    """
    Manages creation of processing run logs in the configured logs folder.

    Each processing run gets a timestamped log file documenting:
    - Which dumps were processed
    - Which files were created/modified
    - Processing duration and cost
    - Any errors that occurred
    """

    def __init__(
        self,
        logs_dir: Path,
        vault_path: Path | None = None,
        vault_service: VaultService | None = None,
    ):
        """
        Initialize log service.

        Args:
            logs_dir: Absolute path to logs directory
            vault_path: Optional absolute path to vault root (for relative path computation)
            vault_service: Optional vault service for dynamic log folder updates
        """
        self.logs_dir = logs_dir
        self.vault_path = vault_path
        self._vault_service = vault_service

    def refresh_logs_dir(self) -> None:
        """Refresh logs directory from current vault settings."""
        if self._vault_service is None:
            return
        self.logs_dir = self._vault_service.logs_path()

    def create_run_log(
        self,
        duration_seconds: float,
        cost_usd: float | None = None,
        error: str | None = None,
    ) -> Path:
        """
        Create a processing run log file.

        Creates the logs directory if it doesn't exist.

        Args:
            duration_seconds: Processing duration in seconds
            cost_usd: API cost in USD (if available)
            error: Error message (if processing failed)

        Returns:
            Path to created log file (relative to vault root)
        """
        self.refresh_logs_dir()
        # Create logs directory on-demand
        self.logs_dir.mkdir(parents=True, exist_ok=True)

        timestamp = datetime.utcnow()
        run_id = timestamp.strftime("%Y-%m-%dT%H-%M-%SZ")
        filename = f"run-{run_id}.md"
        file_path = self.logs_dir / filename

        # Build log content
        content = f"""# Processing Run: {timestamp.isoformat()}Z

## Summary

- **Duration**: {duration_seconds:.1f}s
"""

        # Add cost if available
        if cost_usd is not None:
            content += f"- **Cost**: ${cost_usd:.4f}\n"

        # Add status
        if error:
            content += f"- **Status**: ❌ FAILED\n- **Error**: {error}\n"
        else:
            content += "- **Status**: ✅ SUCCESS\n"

        # Add footer
        content += "\n---\n*Generated by Prime Agent*\n*Changes tracked in git commit*\n"

        # Write log file
        file_path.write_text(content, encoding="utf-8")

        # Return relative path to vault root if available, otherwise absolute path
        if self.vault_path:
            return file_path.relative_to(self.vault_path)
        return file_path

    def create_command_run_log(
        self,
        summary: CommandRunSummary,
        git_summary: CommandRunGitSummary,
    ) -> Path:
        """
        Create a command run log file.

        Args:
            summary: Summary details for the command run
            git_summary: Git sync details for the command run

        Returns:
            Path to created log file (relative to vault root)
        """
        try:
            self.refresh_logs_dir()
            self.logs_dir.mkdir(parents=True, exist_ok=True)
        except OSError as e:
            message = "Failed to create logs directory"
            raise VaultError(
                message,
                context={
                    "operation": "create_command_run_log_dir",
                    "path": str(self.logs_dir),
                },
            ) from e

        timestamp = summary.timestamp.astimezone(UTC)
        timestamp_label = timestamp.strftime("%Y-%m-%dT%H:%M:%SZ")
        file_stamp = timestamp.strftime("%Y-%m-%dT%H-%M-%SZ")
        sanitized_command = self._sanitize_command_name(summary.command_name)
        filename = f"command-{sanitized_command}-{file_stamp}.md"
        file_path = self.logs_dir / filename

        duration_value = (
            "unknown" if summary.duration_seconds is None else f"{summary.duration_seconds:.1f}s"
        )
        cost_value = "unknown" if summary.cost_usd is None else f"${summary.cost_usd:.4f}"
        error_value = summary.error if summary.error else "none"
        scheduled_value = "yes" if summary.scheduled else "no"
        run_id_value = summary.run_id if summary.run_id else "n/a"

        git_outcome = "skipped"
        if git_summary.enabled:
            if git_summary.push_status == "success":
                git_outcome = "pushed"
            elif git_summary.vault_commit_status == "committed":
                git_outcome = "committed"

        lines = [
            f"# Command Run: {timestamp_label}",
            "",
            "## Summary",
            f"- Command: {summary.command_name}",
            f"- Run ID: {run_id_value}",
            f"- Status: {summary.status}",
            f"- Scheduled: {scheduled_value}",
            f"- Duration: {duration_value}",
            f"- Cost USD: {cost_value}",
            f"- Error: {error_value}",
            "",
            "## Git",
            f"- Enabled: {'yes' if git_summary.enabled else 'no'}",
            f"- Outcome: {git_outcome}",
            f"- Pull: {git_summary.pull_status}",
            f"- Changed Files: {git_summary.changed_files_count}",
            f"- Vault Commit: {git_summary.vault_commit_status}",
            f"- Push: {git_summary.push_status}",
        ]

        if git_summary.vault_commit_hash:
            lines.append(f"- Vault Commit Hash: {git_summary.vault_commit_hash}")

        lines.extend(["", "---", "*Generated by Prime Agent*"])
        content = "\n".join(lines) + "\n"

        try:
            file_path.write_text(content, encoding="utf-8")
        except OSError as e:
            message = "Failed to write command run log"
            raise VaultError(
                message,
                context={
                    "operation": "create_command_run_log",
                    "path": str(file_path),
                    "command_name": summary.command_name,
                },
            ) from e

        if self.vault_path:
            return file_path.relative_to(self.vault_path)
        return file_path

    @staticmethod
    def _sanitize_command_name(command_name: str) -> str:
        sanitized = re.sub(r"[^A-Za-z0-9_-]+", "-", command_name).strip("-")
        return sanitized or "command"

    def get_last_run(self) -> dict[str, Any] | None:
        """
        Read the most recent processing run log.

        Returns:
            Dict with run metadata or None if no logs exist
        """
        self.refresh_logs_dir()
        if not self.logs_dir.exists():
            return None

        # Find all run logs
        log_files = sorted(self.logs_dir.glob("run-*.md"), reverse=True)
        if not log_files:
            return None

        # Read the most recent log
        latest_log = log_files[0]
        content = latest_log.read_text(encoding="utf-8")

        # Parse metadata from content
        result: dict[str, Any] = {}

        # Extract timestamp from filename: run-2026-01-02T19-25-00Z.md
        timestamp_match = re.search(r"run-(\d{4}-\d{2}-\d{2}T\d{2}-\d{2}-\d{2}Z)", latest_log.name)
        if timestamp_match:
            timestamp_str = timestamp_match.group(1).replace("-", ":", 2)  # Fix time part
            result["timestamp"] = timestamp_str.replace("T", "T").replace("Z", "Z")

        # Extract duration
        duration_match = re.search(r"\*\*Duration\*\*: ([\d.]+)s", content)
        if duration_match:
            result["duration_seconds"] = float(duration_match.group(1))

        # Extract cost
        cost_match = re.search(r"\*\*Cost\*\*: \$([\d.]+)", content)
        if cost_match:
            result["cost_usd"] = float(cost_match.group(1))

        # Extract status
        if "✅ SUCCESS" in content:
            result["status"] = "success"
        elif "❌ FAILED" in content:
            result["status"] = "failed"
            # Extract error message
            error_match = re.search(r"\*\*Error\*\*: (.+)", content)
            if error_match:
                result["error"] = error_match.group(1).strip()

        # Note: dumps_processed count is not currently tracked in logs
        # Could be added in future if needed
        result["dumps_processed"] = 0

        return result
